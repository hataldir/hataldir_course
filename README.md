## Курсовой проект.

## Тема: Создание процесса непрерывной поставки для приложения с применением практик CI/CD и быстрой обратной связью.

Студент: Лунев Денис

## Описание:

Настроен процесс непрерывной интеграции и непрервыной поставки учебного микросервисного приложения search_engine от express42.
Рабочей платформой для приложения и всех сопутствующих сервисов является кластер Kubernetes в Google Cloud.
Большинство операций для развертывания системы и получения данных выполняется с помощью команды make.

## Screencast:

https://yadi.sk/i/nx17m8HCaCyKFA

## 1. Разворачивание платформы

Логинимся в Google cloud (gcloud auth login). В переменную CRED в Makefile вносим путь к созданному в результате файлу adc.json, а в переменную PROJECT - имя проекта.
Далее создаем инфраструктуру - make install.
Что делает скрипт: 
 - настраиваются параметры gcloud
 - удаляется старая конфигурация terraform (в каталоге terraform)
 - прописывается имя проекта в конфигах terraform
 - создается кластер в GKE при помощи terraform 
 - устанавливается Helm
 - с помощью Helm устанавливается nginx-ingress 
 - через минуту выводится ip-адрес игресса
 - адрес прописывается в values.yaml для Prometheus и Grafana.
 - c помощью Helm устанавливаются Gitlab, Prometheus и Grafana (чарты находятся  в каталоге charts)
 - через минуту выводится адрес веб-интерфейса Gitlab 
 - адрес Gitlab прописывается в Makefile и charts/gitlab/values.yaml
 - адрес и пароль Gitlab выводятся на экран 

## 2. Работа с приложением в Gitlab.

Теперь нужно зайти в веб-интерфейс Gitlab, сменить пароль на более простой (Settings/Password) и получить Access Token (Settings/Access Tokens, имя любое, права максимальные). Этот токен необходимо вписать в Makefile в переменную TOKEN и выполнить make gitlab-push.
Этот скрипт создаст группу hataldir, назначит ей необходимые переменные, создаст и загрузит из каталога src три проекта - crawler, webui и search. В процессе загрузки нужно будет три раза ввести логин root и его пароль

Далее снова придется идти в веб-интерфейс Gitlab и получать еще один токен - в проекте Search в Settings, CI/CD, Pipeline Triggers. Этот токен нужно внести в переменную TOKEN в свойствах группы hataldir.

Теперь в каждом проекте работают пайплайны.

Для crawler и webui пайплайн состоит из следующих стадий:

- build - создание контейнера сервиса

- test - создание контейнера, не запускающего приложение, а выполняющего только тесты

- review - создание отдельного окружения для code review

- cleanup - удаление окружения review (вручную)

- trigger_deploy - запуск пайплайна проекта search

- release - заливка контейнера на докерхаб
  
Для search пайплайн выглядит так:

- staging - создание/обновление окружения staging

- production - создание/обновление окружения production (вручную)

После выполнения пайплайнов мы имеем окружения staging и production, доступные извне. Чтобы узнать их адреса, можно выполнить команду make show-ip.

## 3. Мониторинг

Для мониторинга используются prometheus и grafana. Для мониторинга сервисов развернуты exporters для mongodb и rabbitmq.

Пароль для входа в grafana - otusgitlab.
Доступны два дашборда - стандартный для Kubernetes и свой для мониторинга приложения.
